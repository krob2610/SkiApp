{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from app.DataTransformer import DataTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = DataTransformer(date='2024-02-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.transformed_data_paths['Sony_Xperia_XA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/kuba/SkiApp/data/2023-12-31/Sony_Xperia_XA/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_transformer.device_dataframes['Sony_Xperia_M5'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.device_namespace import FINAL_DF_SENSORS\n",
    "FINAL_DF_SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(FINAL_DF_SENSORS) - set(data_transformer.device_dataframes['Sony_Xperia_M5'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DF_SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from app.device_namespace import DATA_PATH\n",
    "def generate_path_for_final_df(date: str, device: str) -> Path:\n",
    "    \"\"\"Generate path for final dataframe\"\"\"\n",
    "    return Path(DATA_PATH, date, device, \"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in data_transformer.transformed_data_paths.keys():\n",
    "    print(device)\n",
    "    print(generate_path_for_final_df(data_transformer.date, device))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.device_dataframes['HONOR_8X']['TotalAcceleration']['time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_transformer.device_dataframes['HONOR_8X']['Magnetometer']\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.device_dataframes['HONOR_8X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_transformer.device_dataframes['HONOR_8X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['time'] = pd.to_datetime(temp['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp['time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def cut_dataframes_inside_device(device_dataframes: dict,) -> dict:\n",
    "    \"\"\"Cut dataframes to same length\"\"\"\n",
    "    device_dataframes_copy = copy.deepcopy(device_dataframes)\n",
    "    min_time = max_time = None\n",
    "\n",
    "    # Find the global min and max time\n",
    "    for df in device_dataframes_copy.values():\n",
    "        current_min = df['time'].min()\n",
    "        current_max = df['time'].max()\n",
    "        min_time = current_min if min_time is None or current_min > min_time else min_time\n",
    "        max_time = current_max if max_time is None or current_max < max_time else max_time\n",
    "    print(f\"min_time: {min_time}, max_time: {max_time}\")\n",
    "\n",
    "    # Cut each dataframe to the global min and max time\n",
    "    for key, df in device_dataframes_copy.items():\n",
    "        device_dataframes_copy[key] = df[(df['time'] >= min_time) & (df['time'] <= max_time)]\n",
    "\n",
    "    return device_dataframes_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: need adjustment for example if the value is missing in the beginign it will put nan\n",
    "def fill_missing_times(device_dataframes: dict) -> dict:\n",
    "    \"\"\"Fill missing times in dataframes\"\"\"\n",
    "    device_dataframes_copy = copy.deepcopy(device_dataframes)\n",
    "    all_times = set()\n",
    "\n",
    "    # Get all unique times\n",
    "    for df in device_dataframes_copy.values():\n",
    "        all_times.update(df['time'].unique())\n",
    "\n",
    "    # Fill missing times and interpolate other columns\n",
    "    for key, df in device_dataframes_copy.items():\n",
    "        unique_times = set(df['time'].unique())\n",
    "        missing_times = all_times - unique_times\n",
    "        if missing_times:\n",
    "            missing_df = pd.DataFrame(missing_times, columns=['time'])\n",
    "            df = pd.concat([df, missing_df])\n",
    "            df.sort_values('time', inplace=True)\n",
    "            df.set_index('time', inplace=True)\n",
    "            df = df.interpolate(method='time')\n",
    "            device_dataframes_copy[key] = df.reset_index()\n",
    "\n",
    "    return device_dataframes_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = cut_dataframes_inside_device(data_transformer.device_dataframes['HONOR_8X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_missing_time_data = fill_missing_times(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"new data\")\n",
    "for key in new_data.keys():\n",
    "    print(key)\n",
    "    print(new_data[key].size)\n",
    "    print()\n",
    "print(\"filled_missing_time_data\")\n",
    "for key in filled_missing_time_data.keys():\n",
    "    print(key)\n",
    "    print(filled_missing_time_data[key].size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_missing_time_data['TotalAcceleration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_final_df(device_dataframes: dict) -> pd.DataFrame:\n",
    "    \"\"\"Prepare final dataframe that merges all dataframes\"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    # For each dataframe, create a single column where the values are lists of the values in the original columns\n",
    "    for key, df in device_dataframes.items():\n",
    "        df = df.drop(columns='seconds_elapsed', errors='ignore')\n",
    "        df.set_index('time', inplace=True)\n",
    "        df[key] = df.values.tolist()\n",
    "        df = df[[key]]  # Keep only the new column\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Merge all dataframes on the index\n",
    "    final_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = prepare_final_df(filled_missing_time_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in new_data.keys():\n",
    "    print(key)\n",
    "    print(new_data[key].size)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in filled_missing_time_data.keys():\n",
    "    print(key)\n",
    "    print(filled_missing_time_data[key].size)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Magnetometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_transformer.transformed_data['Sony_Xperia_M5'].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer.transformed_data['Sony_Xperia_M5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/2023-12-31/Sony_Xperia_M5/Rules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(list(data_transformer.transformed_data['Sony_Xperia_M5'].values())[0]).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_times_acros_sensors(device_sensor: dict):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file to pd dataframe /Users/kuba/SkiApp/input_data/2023-12-31/HONOR_8X/Accelerometer.csv\n",
    "df = pd.read_csv('/Users/kuba/SkiApp/input_data/2023-12-31/HONOR_8X/Accelerometer.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['time'], unit='ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df.copy()\n",
    "df_time['time'] = pd.to_datetime(df['time'], unit='ns')  # use 'ms' if your timestamps are in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_time['time'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_offset(df: pd.DataFrame, offset: int):\n",
    "    #add offset in ns to time column where offset is ms and time is pandas._libs.tslibs.timestamps.Timestamp\n",
    "    df['time'] = df['time'] + pd.Timedelta(offset, unit='ms')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offset = apply_offset(df_time, 1)\n",
    "df_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.read_csv('/Users/kuba/SkiApp/input_data/2023-12-30/Sony_Xperia_XA/TotalAcceleration.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df2['time'], unit='ns')  # use 'ms' if your timestamps are in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text file /Users/kuba/SkiApp/input_data/2023-12-31/OPPO_AX7/offset.txt and read first file to int\n",
    "f = open('/Users/kuba/SkiApp/input_data/2023-12-31/OPPO_AX7/offset.txt', 'r')\n",
    "offset = int(f.readline())\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Original path\n",
    "path = \"/Users/kuba/SkiApp/input_data/2023-12-30/Sony_Xperia_XA/TotalAcceleration.csv\"\n",
    "\n",
    "# Modify the path\n",
    "new_path = Path(path).relative_to(\"/Users/kuba/SkiApp/input_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = os.path.join(\"data\", new_path)\n",
    "new_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/Users/kuba/SkiApp/input_data/2023-5-30/Soy_Xperia_bA/ToalAccpeleratin.csv\")\n",
    "last_parts = path.parts[-3:]\n",
    "\n",
    "final_path =  Path('data', *last_parts)\n",
    "folders = final_path.parts[:-1]\n",
    "folders = Path(*folders)\n",
    "print(final_path)\n",
    "print(folders)\n",
    "folders.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(final_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(final_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date_directory = Path('/data/2023-12-30/Sony_Xperia_XA/TotalAcceleration.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = new_date_directory.parent\n",
    "\n",
    "# Get the last three components\n",
    "last_three_components = parent_directory.parts[-3:]\n",
    "\n",
    "# Join the components back together into a Path\n",
    "last_three_path = Path(*last_three_components)\n",
    "\n",
    "print(last_three_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date_directory = Path('/data/2023-12-30/Sony_Xperia_XA/TotalAcceleration.csv')\n",
    "\n",
    "new_date_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname('data/2023-12-30/Sony_Xperia_XA'), exist_ok=True)\n",
    "\n",
    "df.to_csv(new_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ski_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
