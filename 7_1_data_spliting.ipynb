{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from app.DataLoader import DataLoader\n",
    "from app.DataLoader import DataLoader\n",
    "from app.DataSpliter import DataSplitter, GranularDataSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\"data/2024-02-25/HUAWEI_MATE/final_df.csv\")\n",
    "data = loader.load_transform_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = DataSplitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splited_data = spliter.split_data(start_time=\"12:44:30\",end_time=\"12:46:45\",offset=\"-0:00:02.5\")\n",
    "# splited_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! by frame\n",
    "# ! also it is right leg so i look on that\n",
    "# ! so the point we are looking is when skier is going straight downhill\n",
    "curves2 = [\n",
    "    \"12:44:30.2\",\n",
    "    \"12:44:33.9\",\n",
    "    \"12:44:37.4\",\n",
    "    \"12:44:40.6\",\n",
    "    \"12:44:41.8\",\n",
    "    \"12:44:46.6\",\n",
    "    \"12:44:56.7\",\n",
    "    \"12:45:00.7\",\n",
    "    \"12:45:03.4\",\n",
    "    \"12:45:07.4\",\n",
    "    \"12:45:10.3\",\n",
    "    \"12:45:16.3\",\n",
    "    \"12:45:19.8\",\n",
    "    \"12:45:23.9\",\n",
    "    \"12:45:28.4\",\n",
    "    \"12:45:31.9\",\n",
    "    \"12:45:37.1\",\n",
    "    \"12:45:44.5\",\n",
    "    \"12:45:49.9\",\n",
    "    \"12:45:53.2\",\n",
    "    \"12:45:58.4\",\n",
    "    \"12:46:00.9\",\n",
    "    \"12:46:06.3\",\n",
    "    \"12:46:10.4\",\n",
    "    \"12:46:13.3\",\n",
    "    \"12:46:15.4\",\n",
    "    \"12:46:17.9\",\n",
    "    \"12:46:20.3\",\n",
    "    \"12:46:22.8\",\n",
    "    \"12:46:25.7\",\n",
    "    \"12:46:31.5\",\n",
    "    \"12:46:34.0\",\n",
    "    \"12:46:36.9\",\n",
    "    \"12:46:43.1\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_R = []\n",
    "curves_L = []\n",
    "for i in range(len(curves2)):\n",
    "    if i % 2 == 0:\n",
    "        curves_L.append(curves2[i])\n",
    "    else:\n",
    "        curves_R.append(curves2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = spliter.split_label_data(start_time=\"12:44:30\",end_time=\"12:46:45\",offset=\"-0:00:01.6\", curves_L=curves_L, curves_R=curves_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only rows from labeled_data where Curve value is true with usage of isin\n",
    "# labeled_data[labeled_data[\"Curve\"].isin([True])]\n",
    "# it also depend by leg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.visualization_utils import draw_plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plotly(labeled_data, \"Orientation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find local extremas in the - also needs to be unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = labeled_data.copy()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podzielenie danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Granular_spliter = GranularDataSplitter(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Granular_spliter.split_into_granular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Granular_spliter.granular_data[\"Orientation\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_value = \"roll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with only one column sensor_value not a series\n",
    "#df_smooth = df[[sensor_value]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.transformers.smoother import Smoother\n",
    "data_smoother = Smoother(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plotly(data_smoother.smooth_data_exponential(span=10, columns=[sensor_value]), \"Orientation\", granular=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plotly(data_smoother.smooth_data_rolling_mean(window_size=10, columns=[sensor_value]), \"Orientation\", granular=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plotly(data_smoother.smooth_data_backward_ma(window_size=10, columns=[sensor_value]), \"Orientation\", granular=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_roll = data_smoother.smooth_data_backward_ma(window_size=10, columns=[sensor_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# () gradient descent with momentum? min max approach\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Literal\n",
    "# Przykład wczytania danych do DataFrame\n",
    "# df = pd.read_csv('twoje_dane.csv')\n",
    "# Zakładam, że kolumna \"roll\" istnieje i index jest poprawny\n",
    "def plot_positions(series, positions, step, curves = None, find_maxima = None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(series, label='Series', color='blue')\n",
    "    plt.scatter(positions, series[positions], color='red', label='Positions')\n",
    "    if curves is not None:\n",
    "        plt.scatter(curves, series[curves], color='green', label='Curves')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    if find_maxima is None:\n",
    "        plt.title('Positions at step {}'.format(step))\n",
    "    else:\n",
    "        extremum = \"maxima\" if find_maxima else \"minima\"\n",
    "        plt.title('Positions at step {} for {}'.format(step, extremum))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def get_curve_points(df:pd.DataFrame, turn: Literal[\"L\", \"R\"] = None):\n",
    "    if turn:\n",
    "        return np.where(df[f'Curve'] == turn)[0].tolist()\n",
    "    return np.where(df['Curve'])[0].tolist()\n",
    "    # Funkcja gradient descent do znajdowania ekstremów\n",
    "\n",
    "def gradient_descent(df, series, normalized_series, normalized_positions,  start_indices, learning_rate, steps, momentum, find_maxima, printing):\n",
    "    velocities = [0 for _ in start_indices]\n",
    "    for step in range(steps):\n",
    "        for i, idx in enumerate(normalized_positions):\n",
    "            ahead_idx = int(min(1, idx + 1/(len(series) - 1)) * (len(series) - 1))\n",
    "            behind_idx = int(max(0, idx - 1/(len(series) - 1)) * (len(series) - 1))\n",
    "\n",
    "            grad = (normalized_series[ahead_idx] - normalized_series[behind_idx]) / 2\n",
    "\n",
    "            # Update velocity and position with momentum\n",
    "            if find_maxima:\n",
    "                velocities[i] = momentum * velocities[i] + learning_rate * grad  # Gradient ascent for maxima\n",
    "            else:\n",
    "                velocities[i] = momentum * velocities[i] - learning_rate * grad  # Gradient descent for minima\n",
    "\n",
    "            new_idx = idx + velocities[i]\n",
    "            new_idx = max(0, min(1, new_idx))  # Ensure new_idx stays within 0-1\n",
    "\n",
    "            normalized_positions[i] = new_idx\n",
    "            #print for step for step\n",
    "            #print(f'point: {i}, ahed_idx: {ahead_idx}, behind_idx: {behind_idx}, grad: {grad}, new_idx: {new_idx}, velocities: {velocities[i]}')\n",
    "        positions = [int(idx * (len(series) - 1)) for idx in normalized_positions]\n",
    "        if step % 10 == 0 and printing:\n",
    "            plot_positions(series, positions, step, get_curve_points(df))\n",
    "    # print(set(history))\n",
    "    positions = [int(idx * (len(series) - 1)) for idx in normalized_positions]\n",
    "    plot_positions(series, positions, \"final\", get_curve_points(df), find_maxima)\n",
    "    return positions\n",
    "\n",
    "def gradient_descent_full(df, start_indices, learning_rate=0.01, steps=1000, momentum=0.98, printing = False):\n",
    "    series = df['roll'].values\n",
    "\n",
    "    positions = start_indices.copy()\n",
    "    #normalize series data to 0-1\n",
    "    normalized_series = (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "    # Normalize start_indices to 0-1\n",
    "    normalized_positions = [idx / (len(series) - 1) for idx in start_indices]\n",
    "\n",
    "    #initial plot\n",
    "    plot_positions(series, positions, \"beginning\", get_curve_points(df))\n",
    "\n",
    "    min_positions = gradient_descent(df, series, normalized_series, normalized_positions,  start_indices, learning_rate, steps, momentum, False, printing)\n",
    "    max_positions = gradient_descent(df, series, normalized_series, normalized_positions,  start_indices, learning_rate, steps, momentum, True, printing)\n",
    "\n",
    "    return min_positions, max_positions\n",
    "\n",
    "\n",
    "\n",
    "# Wybieramy kolumnę \"roll\" z DataFrame\n",
    "\n",
    "# Krok 1: Losowe wybieranie punktów początkowych\n",
    "#np.random.seed(42)  # Ustawienie ziarna losowości dla powtarzalności wyników\n",
    "num_points = 1000\n",
    "start_indices =np.random.randint(1, len(smoothed_roll)-1, size=num_points)  #np.array([800])\n",
    "\n",
    "# Krok 2: Znalezienie ekstremów przy użyciu gradient descent\n",
    "final_positions_min, final_positions_maximums = gradient_descent_full(smoothed_roll, start_indices, printing=False)\n",
    "\n",
    "# # Krok 3: Filtracja najważniejszych ekstremów\n",
    "# unique_positions, counts = np.unique(final_positions, return_counts=True)\n",
    "# threshold = np.percentile(counts, 1)  # Przykładowy próg\n",
    "# important_extrema_indices = unique_positions[counts >= threshold]\n",
    "\n",
    "# Wynik - DataFrame z najważniejszymi ekstremami\n",
    "#important_extrema_smoothed_roll = smoothed_roll.iloc[final_positions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Krok 3: Filtracja najważniejszych ekstremów\n",
    "\n",
    "def filter_extremes(final_positions):\n",
    "    unique_positions, counts = np.unique(final_positions, return_counts=True)\n",
    "    threshold = np.percentile(counts, 75)  # Przykładowy próg\n",
    "    important_extrema_indices = unique_positions[counts >= threshold]\n",
    "    return important_extrema_indices\n",
    "\n",
    "# unique_positions, counts = np.unique(final_positions_min, return_counts=True)\n",
    "# threshold = np.percentile(counts, 75)  # Przykładowy próg\n",
    "# important_extrema_indices = unique_positions[counts >= threshold]\n",
    "\n",
    "# Wynik - DataFrame z najważniejszymi ekstremami\n",
    "#important_extrema_smoothed_roll = smoothed_roll.iloc[final_positions]\n",
    "important_min = filter_extremes(final_positions_min)\n",
    "important_max = filter_extremes(final_positions_maximums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_positions(smoothed_roll['roll'].values, important_min, \"mins\", get_curve_points(smoothed_roll, \"L\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_positions(smoothed_roll['roll'].values, important_max, \"max\", get_curve_points(smoothed_roll, \"R\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(smoothed_roll['Curve'].isin([\"R\"]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Later need to be adjusted /left/right turs for now there is just a \"turn\"\n",
    "def get_distance(df, positions, turn ):\n",
    "\n",
    "    curves = np.where(smoothed_roll['Curve'].isin([turn]))[0]\n",
    "    positions = np.sort(positions)\n",
    "    curves = np.sort(curves)\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    for i in range(len(positions)):\n",
    "        j = 0\n",
    "        while j < len(curves)-1 and abs(positions[i] - curves[j]) > abs(positions[i] - curves[j+1]):\n",
    "            j += 1\n",
    "        distances.append(abs(positions[i] - curves[j]))\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_R = get_distance(smoothed_roll, important_max, \"R\")\n",
    "distances_L = get_distance(smoothed_roll, important_min, \"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['roll'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "local_maxima_indices = argrelextrema(smoothed_roll[sensor_value].values, np.greater)[0]\n",
    "local_maxima = smoothed_roll.iloc[local_maxima_indices]\n",
    "\n",
    "# Znalezienie lokalnych minimów\n",
    "local_minima_indices = argrelextrema(smoothed_roll[sensor_value].values, np.less)[0]\n",
    "local_minima = smoothed_roll.iloc[local_minima_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(smoothed_roll.index, smoothed_roll[sensor_value], label=sensor_value, color='blue')\n",
    "plt.scatter(local_maxima.index, local_maxima[sensor_value], color='red', label='Local Maxima', zorder=5)\n",
    "plt.scatter(local_minima.index, local_minima[sensor_value], color='green', label='Local Minima', zorder=5)\n",
    "plt.title(f'{sensor_value} with Local Extrema')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel(sensor_value)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ski_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
